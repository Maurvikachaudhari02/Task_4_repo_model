{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Task-4: Spam Detection using scikit-learn\n", "Objective: Build a classifier (spam vs ham) using scikit-learn, evaluate it, and save the trained pipeline."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# !pip install -q pandas scikit-learn matplotlib nltk joblib\n", "\n", "import os, pandas as pd, numpy as np\n", "import matplotlib.pyplot as plt\n", "import joblib\n", "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n", "from sklearn.pipeline import Pipeline\n", "from sklearn.feature_extraction.text import TfidfVectorizer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.svm import LinearSVC\n", "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n", "import warnings\n", "warnings.filterwarnings('ignore')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["url = 'https://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv'\n", "df = pd.read_csv(url, sep='\\t', header=None, names=['label','text'])\n", "\n", "df['label'] = df['label'].str.lower().str.strip()\n", "df['text'] = df['text'].astype(str)\n", "df['label_num'] = df['label'].map({'ham':0, 'spam':1})\n", "print(\"Dataset shape:\", df.shape)\n", "df.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(df['label'].value_counts())\n", "df['text_len'] = df['text'].str.split().apply(len)\n", "plt.hist(df['text_len'], bins=30)\n", "plt.xlabel('Words per message'); plt.ylabel('Count'); plt.title('Message length distribution')\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X = df['text']\n", "y = df['label_num']\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n", "print(\"Train/test sizes:\", X_train.shape, X_test.shape)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["pipe = Pipeline([\n", "    ('tfidf', TfidfVectorizer(stop_words='english')),\n", "    ('clf', LogisticRegression(solver='liblinear', max_iter=500))\n", "])\n", "\n", "param_grid = {\n", "    'tfidf__ngram_range': [(1,1),(1,2)],\n", "    'tfidf__min_df': [1,2],\n", "    'clf__C': [0.1, 1]\n", "}\n", "\n", "grid = GridSearchCV(pipe, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1)\n", "grid.fit(X_train, y_train)\n", "print(\"Best params:\", grid.best_params_)\n", "best_model = grid.best_estimator_"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["y_pred = best_model.predict(X_test)\n", "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "print(\"Precision:\", precision_score(y_test, y_pred))\n", "print(\"Recall:\", recall_score(y_test, y_pred))\n", "print(\"F1:\", f1_score(y_test, y_pred))\n", "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, target_names=['ham','spam']))\n", "\n", "cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n", "print(\"Confusion matrix:\\n\", cm)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["model_path = 'spam_classifier_pipeline.joblib'\n", "joblib.dump(best_model, model_path)\n", "print(\"Saved model to\", model_path)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["loaded = joblib.load(model_path)\n", "examples = [\"Congratulations! You won a prize.\", \"Hey, are you free today?\"]\n", "preds = loaded.predict(examples)\n", "for t,p in zip(examples,preds):\n", "    print(p, \"-\", t)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n", "- Logistic Regression with TF-IDF performed well on spam classification.\n", "- Improvements could include more preprocessing, handling class imbalance, or trying deep learning models.\n", "- Deliverables: notebook, saved model, requirements.txt, README.md."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 2}